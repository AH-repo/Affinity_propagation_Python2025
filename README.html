<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="Docutils 0.22.3: https://docutils.sourceforge.io/" />
<title>README.rst</title>
<style type="text/css">

/*
:Author: David Goodger (goodger@python.org)
:Id: $Id: html4css1.css 9511 2024-01-13 09:50:07Z milde $
:Copyright: This stylesheet has been placed in the public domain.

Default cascading style sheet for the HTML output of Docutils.
Despite the name, some widely supported CSS2 features are used.

See https://docutils.sourceforge.io/docs/howto/html-stylesheets.html for how to
customize this style sheet.
*/

/* used to remove borders from tables and images */
.borderless, table.borderless td, table.borderless th {
  border: 0 }

table.borderless td, table.borderless th {
  /* Override padding for "table.docutils td" with "! important".
     The right padding separates the table cells. */
  padding: 0 0.5em 0 0 ! important }

.first {
  /* Override more specific margin styles with "! important". */
  margin-top: 0 ! important }

.last, .with-subtitle {
  margin-bottom: 0 ! important }

.hidden {
  display: none }

.subscript {
  vertical-align: sub;
  font-size: smaller }

.superscript {
  vertical-align: super;
  font-size: smaller }

a.toc-backref {
  text-decoration: none ;
  color: black }

blockquote.epigraph {
  margin: 2em 5em ; }

dl.docutils dd {
  margin-bottom: 0.5em }

object[type="image/svg+xml"], object[type="application/x-shockwave-flash"] {
  overflow: hidden;
}

/* Uncomment (and remove this text!) to get bold-faced definition list terms
dl.docutils dt {
  font-weight: bold }
*/

div.abstract {
  margin: 2em 5em }

div.abstract p.topic-title {
  font-weight: bold ;
  text-align: center }

div.admonition, div.attention, div.caution, div.danger, div.error,
div.hint, div.important, div.note, div.tip, div.warning {
  margin: 2em ;
  border: medium outset ;
  padding: 1em }

div.admonition p.admonition-title, div.hint p.admonition-title,
div.important p.admonition-title, div.note p.admonition-title,
div.tip p.admonition-title {
  font-weight: bold ;
  font-family: sans-serif }

div.attention p.admonition-title, div.caution p.admonition-title,
div.danger p.admonition-title, div.error p.admonition-title,
div.warning p.admonition-title, .code .error {
  color: red ;
  font-weight: bold ;
  font-family: sans-serif }

/* Uncomment (and remove this text!) to get reduced vertical space in
   compound paragraphs.
div.compound .compound-first, div.compound .compound-middle {
  margin-bottom: 0.5em }

div.compound .compound-last, div.compound .compound-middle {
  margin-top: 0.5em }
*/

div.dedication {
  margin: 2em 5em ;
  text-align: center ;
  font-style: italic }

div.dedication p.topic-title {
  font-weight: bold ;
  font-style: normal }

div.figure {
  margin-left: 2em ;
  margin-right: 2em }

div.footer, div.header {
  clear: both;
  font-size: smaller }

div.line-block {
  display: block ;
  margin-top: 1em ;
  margin-bottom: 1em }

div.line-block div.line-block {
  margin-top: 0 ;
  margin-bottom: 0 ;
  margin-left: 1.5em }

div.sidebar {
  margin: 0 0 0.5em 1em ;
  border: medium outset ;
  padding: 1em ;
  background-color: #ffffee ;
  width: 40% ;
  float: right ;
  clear: right }

div.sidebar p.rubric {
  font-family: sans-serif ;
  font-size: medium }

div.system-messages {
  margin: 5em }

div.system-messages h1 {
  color: red }

div.system-message {
  border: medium outset ;
  padding: 1em }

div.system-message p.system-message-title {
  color: red ;
  font-weight: bold }

div.topic {
  margin: 2em }

h1.section-subtitle, h2.section-subtitle, h3.section-subtitle,
h4.section-subtitle, h5.section-subtitle, h6.section-subtitle {
  margin-top: 0.4em }

h1.title {
  text-align: center }

h2.subtitle {
  text-align: center }

hr.docutils {
  width: 75% }

img.align-left, .figure.align-left, object.align-left, table.align-left {
  clear: left ;
  float: left ;
  margin-right: 1em }

img.align-right, .figure.align-right, object.align-right, table.align-right {
  clear: right ;
  float: right ;
  margin-left: 1em }

img.align-center, .figure.align-center, object.align-center {
  display: block;
  margin-left: auto;
  margin-right: auto;
}

table.align-center {
  margin-left: auto;
  margin-right: auto;
}

.align-left {
  text-align: left }

.align-center {
  clear: both ;
  text-align: center }

.align-right {
  text-align: right }

/* reset inner alignment in figures */
div.align-right {
  text-align: inherit }

/* div.align-center * { */
/*   text-align: left } */

.align-top    {
  vertical-align: top }

.align-middle {
  vertical-align: middle }

.align-bottom {
  vertical-align: bottom }

ol.simple, ul.simple {
  margin-bottom: 1em }

ol.arabic {
  list-style: decimal }

ol.loweralpha {
  list-style: lower-alpha }

ol.upperalpha {
  list-style: upper-alpha }

ol.lowerroman {
  list-style: lower-roman }

ol.upperroman {
  list-style: upper-roman }

p.attribution {
  text-align: right ;
  margin-left: 50% }

p.caption {
  font-style: italic }

p.credits {
  font-style: italic ;
  font-size: smaller }

p.label {
  white-space: nowrap }

p.rubric {
  font-weight: bold ;
  font-size: larger ;
  color: maroon ;
  text-align: center }

p.sidebar-title {
  font-family: sans-serif ;
  font-weight: bold ;
  font-size: larger }

p.sidebar-subtitle {
  font-family: sans-serif ;
  font-weight: bold }

p.topic-title {
  font-weight: bold }

pre.address {
  margin-bottom: 0 ;
  margin-top: 0 ;
  font: inherit }

pre.literal-block, pre.doctest-block, pre.math, pre.code {
  margin-left: 2em ;
  margin-right: 2em }

pre.code .ln { color: gray; } /* line numbers */
pre.code, code { background-color: #eeeeee }
pre.code .comment, code .comment { color: #5C6576 }
pre.code .keyword, code .keyword { color: #3B0D06; font-weight: bold }
pre.code .literal.string, code .literal.string { color: #0C5404 }
pre.code .name.builtin, code .name.builtin { color: #352B84 }
pre.code .deleted, code .deleted { background-color: #DEB0A1}
pre.code .inserted, code .inserted { background-color: #A3D289}

span.classifier {
  font-family: sans-serif ;
  font-style: oblique }

span.classifier-delimiter {
  font-family: sans-serif ;
  font-weight: bold }

span.interpreted {
  font-family: sans-serif }

span.option {
  white-space: nowrap }

span.pre {
  white-space: pre }

span.problematic, pre.problematic {
  color: red }

span.section-subtitle {
  /* font-size relative to parent (h1..h6 element) */
  font-size: 80% }

table.citation {
  border-left: solid 1px gray;
  margin-left: 1px }

table.docinfo {
  margin: 2em 4em }

table.docutils {
  margin-top: 0.5em ;
  margin-bottom: 0.5em }

table.footnote {
  border-left: solid 1px black;
  margin-left: 1px }

table.docutils td, table.docutils th,
table.docinfo td, table.docinfo th {
  padding-left: 0.5em ;
  padding-right: 0.5em ;
  vertical-align: top }

table.docutils th.field-name, table.docinfo th.docinfo-name {
  font-weight: bold ;
  text-align: left ;
  white-space: nowrap ;
  padding-left: 0 }

/* "booktabs" style (no vertical lines) */
table.docutils.booktabs {
  border: 0px;
  border-top: 2px solid;
  border-bottom: 2px solid;
  border-collapse: collapse;
}
table.docutils.booktabs * {
  border: 0px;
}
table.docutils.booktabs th {
  border-bottom: thin solid;
  text-align: left;
}

h1 tt.docutils, h2 tt.docutils, h3 tt.docutils,
h4 tt.docutils, h5 tt.docutils, h6 tt.docutils {
  font-size: 100% }

ul.auto-toc {
  list-style-type: none }

</style>
</head>
<body>
<div class="document">


<!-- These are examples of badges you might want to add to your README:
please update the URLs accordingly

 .. image:: https://api.cirrus-ci.com/github/<USER>/AffinityPropagation.svg?branch=main
     :alt: Built Status
     :target: https://cirrus-ci.com/github/<USER>/AffinityPropagation
 .. image:: https://readthedocs.org/projects/AffinityPropagation/badge/?version=latest
     :alt: ReadTheDocs
     :target: https://AffinityPropagation.readthedocs.io/en/stable/
 .. image:: https://img.shields.io/coveralls/github/<USER>/AffinityPropagation/main.svg
     :alt: Coveralls
     :target: https://coveralls.io/r/<USER>/AffinityPropagation
 .. image:: https://img.shields.io/pypi/v/AffinityPropagation.svg
     :alt: PyPI-Server
     :target: https://pypi.org/project/AffinityPropagation/
 .. image:: https://img.shields.io/conda/vn/conda-forge/AffinityPropagation.svg
     :alt: Conda-Forge
     :target: https://anaconda.org/conda-forge/AffinityPropagation
 .. image:: https://pepy.tech/badge/AffinityPropagation/month
     :alt: Monthly Downloads
     :target: https://pepy.tech/project/AffinityPropagation
 .. image:: https://img.shields.io/twitter/url/http/shields.io.svg?style=social&label=Twitter
     :alt: Twitter
     :target: https://twitter.com/AffinityPropagation -->
<a class="reference external image-reference" href="https://pyscaffold.org/">
<img alt="Project generated with PyScaffold" src="https://img.shields.io/badge/-PyScaffold-005CA0?logo=pyscaffold" />
</a>
<div class="line-block">
<div class="line"><br /></div>
</div>
<div class="section" id="affinitypropagation">
<h1>AffinityPropagation</h1>
<p># Affinity Propagation Clustering</p>
<p>## Introduction</p>
<p>Affinity Propagation is a clustering algorithm developed by Frey and Dueck (2007) that automatically determines the optimal number of clusters in a dataset. Unlike traditional methods such as K-means which require prior specification of cluster count, this algorithm identifies exemplars (representative data points) through iterative message passing between all pairs of data points.</p>
<p>The algorithm is particularly useful when the underlying number of clusters is unknown and when cluster centers need to be actual data points rather than computed centroids.</p>
<p>## Theoretical Background</p>
<p>Affinity Propagation treats all data points as potential exemplars and iteratively exchanges messages until a good set of exemplars and corresponding clusters emerges. The algorithm operates on a similarity matrix and updates two key matrices - responsibility and availability - until convergence.</p>
<p>### Core Concepts</p>
<p>The algorithm is based on two types of messages:</p>
<p><strong>Responsibility r(i,k)</strong>: Reflects how well-suited point k is to serve as the exemplar for point i, taking into account other potential exemplars for point i.</p>
<p><strong>Availability a(i,k)</strong>: Reflects how appropriate it would be for point i to choose point k as its exemplar, considering the support from other points that k should be an exemplar.</p>
<p>## Algorithm Description</p>
<p>### Similarity Matrix Construction</p>
<p>The similarity matrix S is constructed where S(i,j) represents the negative squared Euclidean distance between points i and j. This can be expressed as S(i,j) = -||xi - xj||^2. Higher values indicate greater similarity between points.</p>
<p>The diagonal elements S(k,k) are set to a preference value, which influences how likely each point is to become an exemplar. Higher preference values result in more clusters.</p>
<p>### Message Passing Procedure</p>
<p>The algorithm iteratively updates the responsibility and availability matrices according to the following rules:</p>
<p><strong>Responsibility Update</strong>:
r(i,k) is updated as the similarity S(i,k) minus the maximum of availability plus similarity for all other candidate exemplars. Mathematically, r(i,k) = S(i,k) - max{a(i,k') + S(i,k')} where k' ranges over all points except k.</p>
<p>This update reflects the degree to which point k is suited to be the exemplar for point i, relative to other candidates.</p>
<p><strong>Availability Update</strong>:
For i ≠ k, availability a(i,k) is set to the minimum of zero and r(k,k) plus the sum of positive responsibilities that k receives from points other than i and k.</p>
<p>For the self-availability a(k,k), it equals the sum of positive responsibilities that k receives from all other points. This reflects the accumulated evidence for point k being an exemplar based on how well-suited it is for other points.</p>
<p>### Damping Factor</p>
<p>To avoid numerical oscillations during message updates, a damping factor λ (typically between 0.5 and 0.9) is applied. The updated values are computed as weighted averages of the old and newly computed values:</p>
<p>R_new = λ × R_old + (1 - λ) × R_computed
A_new = λ × A_old + (1 - λ) × A_computed</p>
<p>### Exemplar Identification</p>
<p>After each iteration, the exemplars are identified as those points k for which r(k,k) + a(k,k) &gt; 0. The criterion matrix E = R + A is computed, and points with positive diagonal elements in E are designated as exemplars.</p>
<p>### Cluster Assignment</p>
<p>Once exemplars are identified, each non-exemplar point i is assigned to its most similar exemplar k*, where k* = argmax_k S(i,k) over all exemplars k.</p>
<p>### Convergence</p>
<p>The algorithm terminates when the set of exemplars remains unchanged for a specified number of iterations (typically 15) or when the maximum iteration count is reached.</p>
<p>## Implementation Parameters</p>
<ul class="simple">
<li><strong>damping</strong>: Controls the rate of message update, range [0.5, 1.0], default 0.5</li>
<li><strong>max_iter</strong>: Maximum number of iterations allowed, default 200</li>
<li><strong>convergence_iter</strong>: Number of iterations with unchanged exemplars required for convergence, default 15</li>
<li><strong>preference</strong>: Initial preference for all points, affects cluster count. If None, median similarity is used</li>
<li><strong>affinity</strong>: Method for computing similarity matrix, either 'euclidean' or 'precomputed'</li>
</ul>
<p>## Usage Example
```python
import numpy as np
from affinity_propagation import AffinityPropagation</p>
<p># Generate sample data
np.random.seed(42)
X = np.random.randn(150, 2)</p>
<p># Initialize and fit model
model = AffinityPropagation(damping=0.7, preference=-50, max_iter=200)
labels = model.fit_predict(X)</p>
<p># Visualize clustering results
model.plot()</p>
<p># Access results
n_clusters = len(np.unique(labels))
exemplar_indices = <a href="#system-message-5"><span class="problematic" id="problematic-5">model.cluster_centers_indices_</span></a>
print(f&quot;Number of clusters found: {n_clusters}&quot;)
print(f&quot;Exemplar indices: {exemplar_indices}&quot;)
```</p>
<p>## Computational Complexity</p>
<p>The algorithm has time complexity O(N^2 T) where N is the number of data points and T is the number of iterations until convergence. Space complexity is O(N^2) due to storage of the similarity, responsibility, and availability matrices.</p>
<p>This quadratic complexity makes the algorithm computationally intensive for large datasets, typically limiting practical application to datasets with fewer than several thousand points.</p>
<p>## Advantages and Limitations</p>
<p>### Advantages</p>
<ol class="arabic simple">
<li>Automatic cluster number determination without prior specification</li>
<li>Real data points serve as cluster centers rather than abstract centroids</li>
<li>Can discover clusters of varying shapes and densities</li>
<li>All points are considered as potential exemplars, providing flexibility</li>
</ol>
<p>### Limitations</p>
<ol class="arabic simple">
<li>High computational and memory requirements due to O(N^2) complexity</li>
<li>Sensitive to parameter selection, particularly preference and damping values</li>
<li>May converge slowly or oscillate indefinitely without proper damping</li>
<li>Results can vary based on random initialization in some implementations</li>
</ol>
<p>## Comparison with K-means</p>
<p>Unlike K-means which requires specifying k and computes abstract centroids, Affinity Propagation automatically determines cluster count and uses actual data points as representatives. However, K-means has significantly lower computational complexity O(NkT) and scales better to large datasets.</p>
<p>## References</p>
<p>Frey, B. J., &amp; Dueck, D. (2007). Clustering by passing messages between data points. Science, 315(5814), 972-976.</p>
<p>Dueck, D., &amp; Frey, B. J. (2007). Non-metric affinity propagation for unsupervised image categorization. In IEEE 11th International Conference on Computer Vision (pp. 1-8).</p>
<p>## Implementation Notes</p>
<p>This implementation follows the original algorithm specification with standard Euclidean distance for similarity computation. The preference parameter can be adjusted to control cluster granularity, with lower values typically resulting in fewer, larger clusters.</p>
<p>The damping factor is critical for convergence - values too low may cause oscillation while values too high may slow convergence. The default value of 0.5 provides a reasonable starting point for most applications.</p>
<div class="section" id="note">
<span id="pyscaffold-notes"></span><h2>Note</h2>
<p>This project has been set up using PyScaffold 4.6. For details and usage
information on PyScaffold see <a class="reference external" href="https://pyscaffold.org/">https://pyscaffold.org/</a>.</p>
</div>
</div>
<div class="system-messages section">
<h1>Docutils System Messages</h1>
<div class="system-message" id="system-message-5">
<p class="system-message-title">System Message: ERROR/3 (<tt class="docutils">C:/Users/User/PycharmProjects/PythonProject/AffinityPropagation/README.rst</tt>, line 122); <em><a href="#problematic-5">backlink</a></em></p>
Unknown target name: &quot;model.cluster_centers_indices&quot;.</div>
</div>
</div>
</body>
</html>
